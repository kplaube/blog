---
title: "Do WSGI ao ASGI - Parte 1"
date: 2021-03-01 17:45:00
modified: 2023-11-13 16:39:00
tags:
  [
    "python",
    "django",
    "wsgi",
    "asgi",
    "async",
    "asyncio",
    "threads",
    "paralelismo",
    "concorrencia",
    "desenvolvimento-web",
  ]
slug: do-wsgi-ao-asgi-parte-1
thumbnail: /media/python-logo-2.png
---

O [_Django 3_](/tag/django.html "Leia mais sobre Django") veio para sacudir as estruturas. Parece que foi ontem, mas
a vers√£o j√° est√° a√≠ desde 2019. Entre todas as suas adi√ß√µes,
a de maior destaque certamente √© a ado√ß√£o de capacidades _async_ atrav√©s do _ASGI_ (_Asynchronous Server Gateway Interface_).

Se voc√™, assim como eu, n√£o v√™ motivos para largar o [_WSGI_](/2012/11/02/entendendo-o-cgi-fastcgi-e-wsgi.html "Entendendo o CGI, FastCGI e WSGI") (_Web Server Gateway Interface_),
e ainda tem dificuldades para compreender o que √© de fato esse novo _Gateway Interface_, vem comigo.

Mas antes de mergulhar na pr√°tica, essa √© uma boa oportunidade para falarmos sobre _async_, _threads_, concorr√™ncia e paralelismo.

## CPU, cores, processos e threads

O _CPU_ √© a cabe√ßa por tr√°s de todo o processamento. Ele funciona em ciclos que correspondem ao tempo necess√°rio para a execu√ß√£o de uma opera√ß√£o. Um
_CPU_ pode ter m√∫ltiplos _cores_, e cada _core_ √© capaz de executar m√∫ltiplos processos.

No caso dos processos _Python_, cada um possui um interpretador _Python_, _memory space_, e o famigerado _GIL_ (mais a seguir).

Quando executamos o processo _Python_, ele:

- Pode executar m√∫ltiplos subprocessos.
- A partir da _main thread_, pode iniciar m√∫ltiplas _threads_.

![Diagrama mostrando a diferen√ßa entre multithreading e multiprocessing](/media/python-thread-multiprocessing.png "Multithreading vs. Multiprocessing")

Uma _thread_ √© uma unidade de execu√ß√£o dentro de um processo. Cada _thread_ utiliza o espa√ßo de mem√≥ria do mesmo, compartilhando-o com as demais.

## Concorr√™ncia e paralelismo

A motiva√ß√£o por tr√°s do uso de _threads_ e subprocessos √© permitir que diferentes tarefas aconte√ßam ao mesmo tempo. E "ao mesmo tempo" pode significar
que a inten√ß√£o seja de um resultado simult√¢neo, mas na pr√°tica, n√£o necessariamente ocorrendo no mesmo instante.

Complicado? Para fins did√°ticos
vamos utilizar o exemplo proposto pelo [_FinTechExplained_](https://medium.com/fintechexplained/advanced-python-concurrency-and-parallelism-82e378f26ced "Advanced Python: Concurrency And Parallelism"):

> Eu estou esperando 10 amigos para almo√ßar, e eu tenho 3 horas para cozinhar o suficiente para 10 pessoas.

Os passos para um prato s√£o:

- Come√ßo lavando os vegetais (~5 minutos);
- Corto os vegetais (~13 minutos);
- Cozinho os mesmos (~30 minutos);
- Sirvo (~2 minutos).

![Fluxograma mostrando os passos iniciando pela lavagem e terminando em servir](/media/cooking-sync.png "O fluxo de forma linear")

Imagine que temos apenas uma boca no fog√£o, e que s√≥ conseguimos cozinhar um prato por vez.
Se pensarmos de forma linear, um prato leva aproximadamente 50 minutos para ficar pronto. Se multiplicarmos
pelo n√∫mero de amigos, precisaremos de `8 horas` cozinhando para atender a demanda.

### Concorr√™ncia

Para reduzir o tempo total, uma possibilidade √© adquirirmos outro fog√£o. Continuamos
a cortar os vegetais de forma sequencial, mas o passo de cozimento pode acontecer de uma
maneira na qual eu possa ter as duas bocas funcionando, e checar periodicamente o estado de cozimento
de cada prato.

![Com duas bocas, consigo ter concorr√™ncia no cozimento](/media/concurrency.png "Com duas bocas, consigo ter concorr√™ncia no cozimento")

[_Diogo M. Martins_ define concorr√™ncia como](https://diogommartins.wordpress.com/2017/04/07/concorrencia-e-paralelismo-threads-multiplos-processos-e-asyncio-parte-1/ "CONCORR√äNCIA E PARALELISMO ‚Äì THREADS, M√öLTIPLOS PROCESSOS E ASYNCIO ‚Äì PARTE 1"):

> Quando duas ou mais tarefas podem come√ßar a ser executadas e terminar em espa√ßos de tempo que se sobrep√µem,
> n√£o significando que elas precisam estar em execu√ß√£o necessariamente no mesmo instante.

Logo, ao inv√©s de 60 minutos (2 pratos x 30 minutos de cozimento) podemos alcan√ßar um tempo menor.

### Paralelismo

Com dois cozinheiros, cada um trabalhando de sua casa, conseguimos dividir a carga, e portanto, em `4 horas` seremos capazes de atender a demanda.

![Com dois cozinheiros, consigo paralelizar o trabalho](/media/parallelism.png "Com dois cozinheiros, consigo paralelizar o trabalho")

E talvez essa seja a forma mais simplista de definir paralelismo: Quando duas ou mais tarefas s√£o executadas literalmente ao mesmo tempo.

Bom... se a motiva√ß√£o por tr√°s das _threads_ e subprocessos √© permitir que tarefas aconte√ßam ao mesmo tempo, podemos
utilizar qualquer um deles para alcan√ßar paralelismo, certo?

![Diagrama com a diferen√ßa de execu√ß√£o entre concorr√™ncia e paralelismo](/media/concurrency-parallelism.jpg "Uma imagem pode valer mais que mil palavras (stackoverflow.com)")

N√£o necessariamente.

## GIL (Global Interpreter Lock)

O _Python Global Interpreter Lock_ (ou _GIL_) √© uma "trava" que permite que apenas uma _thread_ tenha controle sobre o interpretador. Ou seja,
apenas uma _thread_ executa por vez, mesmo em uma arquitetura _multi-thread_ com mais de um _core_.

Infame? No m√≠nimo. Mas h√° uma boa motiva√ß√£o para essa trava existir. De forma resumida, ela est√° relacionada
com a forma como a linguagem [gerencia mem√≥ria](https://stackify.com/python-garbage-collection/ "Leia sobre o gerenciamento de mem√≥ria em Python"), e previne
problemas de _memory leak_ e _deadlocks_, ao mesmo tempo que oferece n√∫meros interessantes de performance.

O artigo do _RealPython_,
["What Is the Python Global Interpreter Lock (GIL)?"](https://realpython.com/python-gil/ "Leia o artigo na √≠ntegra"),
√© uma excelente refer√™ncia para voc√™ saber tudo a respeito.

Para o bem ou para o mal, na pr√°tica voc√™ n√£o consegue atingir paralelismo utilizando _threads_ em _Python_ (e note, essa √© uma realidade espec√≠fica da linguagem).
Ainda assim, fazer `multithreading` te dar√° o resultado concorrente que voc√™ deseja.

![Fluxograma de como a GIL funciona](/media/gil-lock.png "GIL e o gerenciamento de threads")

E como conseguimos de fato paralelismo ent√£o? Utilizando processos!

Com a biblioteca de `multiprocessing`, ao inv√©s de iniciarmos
uma _thread_, iniciamos um novo processo _Python_ que se encarregar√° de executar o que for requisitado. E citando o in√≠cio desse artigo:

> No caso dos processos Python, cada um possui um interpretador Python, memory space, e o famigerado GIL.

Logo, n√£o sofremos a limita√ß√£o da trava uma vez que estamos
falando de processos √† parte, gerenciados pelo Sistema Operacional.

## Multithreading e Multiprocessing

Para ficar um pouco mais claro, vamos a um exemplo pr√°tico. Verificaremos o tamanho de alguns sites.

A forma mais recomendada de dar os primeiros passos com _threads_ em _Python_ √© atrav√©s da biblioteca `concurrent.futures`:

```python
# thread.py

import concurrent.futures
import urllib.request

URLS = ['http://www.foxnews.com/',
        'http://www.cnn.com/',
        'http://www.bbc.co.uk/',]

def load_url(url, timeout):
    with urllib.request.urlopen(url, timeout=timeout) as conn:
        return conn.read()

def main():
    with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
        future_to_url = {executor.submit(load_url, url, 60): url for url in URLS}

        for future in concurrent.futures.as_completed(future_to_url):
            url = future_to_url[future]
            data = future.result()
            print('%r tem %d bytes' % (url, len(data)))


if __name__ == "__main__":
    main()
```

Caso voc√™ queira saber mais sobre a sintaxe, vale a pena conferir a [documenta√ß√£o
oficial do _Python_](https://docs.python.org/3.6/library/concurrent.futures.html#concurrent.futures.ThreadPoolExecutor "Leia sobre ThreadPoolExecutor").

A execu√ß√£o deve apresentar um resultado parecido com o abaixo:

```text
'http://www.bbc.co.uk/' tem 361696 bytes
'http://www.cnn.com/' tem 1143256 bytes
'http://www.foxnews.com/' tem 334772 bytes
```

O `ThreadPoolExecutor` estende do tipo `Executor`. Possu√≠mos tamb√©m o filho `ProcessPoolExecutor`, que tem uma interface semelhante, mas utiliza o m√≥dulo `multiprocessing`
por baixo dos panos:

```python
# process.py

import concurrent.futures
import urllib.request

URLS = ['http://www.foxnews.com/',
        'http://www.cnn.com/',
        'http://www.bbc.co.uk/',]

def load_url(url, timeout):
    with urllib.request.urlopen(url, timeout=timeout) as conn:
        return conn.read()

def main():
    with concurrent.futures.ProcessPoolExecutor(max_workers=3) as executor:
        future_to_url = {executor.submit(load_url, url, 60): url for url in URLS}

        for future in concurrent.futures.as_completed(future_to_url):
            url = future_to_url[future]
            data = future.result()
            print('%r tem %d bytes' % (url, len(data)))


if __name__ == "__main__":
    main()
```

Para maiores detalhes sobre a implementa√ß√£o, [confira a documenta√ß√£o do _ProcessPoolExecutor_](https://docs.python.org/3.6/library/concurrent.futures.html#concurrent.futures.ProcessPoolExecutor "Leia mais sobre").

Com aux√≠lio da ferramenta de linha de comando `time`, podemos calcular quanto tempo
cada _script_ leva para executar as tarefas concorrentemente:

```text
$ time python thread.py
'http://www.bbc.co.uk/' tem 360652 bytes
'http://www.foxnews.com/' tem 336778 bytes
'http://www.cnn.com/' tem 1143341 bytes
python thread.py  0.15s user 0.06s system 38% cpu 0.555 total

$ time python process.py
'http://www.bbc.co.uk/' tem 360652 bytes
'http://www.cnn.com/' tem 1143341 bytes
'http://www.foxnews.com/' tem 336779 bytes
python process.py  0.41s user 0.12s system 74% cpu 0.715 total
```

E surpreendentemente vemos que o exemplo com _threads_ (`0.15s`) leva
menos tempo que o com subprocessos (`0.41s`).

## I/O-bound e CPU-bound

Pela ideia de que _threads_ em _Python_ n√£o s√£o paralelas, podemos chegar erroneamente √† conclus√£o de que _multiprocessing_ √© a solu√ß√£o
definitiva.

Depende do tipo de problema que estamos tentando resolver. H√° duas categorias distintas
que influenciam na decis√£o:

- Problemas _CPU-bound_: Onde o progresso do processo √© limitado pela velocidade da _CPU_ .
- Problemas _I/O-bound_: O progresso √© limitado pela velocidade do subsistema de entrada/sa√≠da.

Um exemplo do primeiro √© um conjunto de opera√ß√µes matem√°ticas complexas, que dependem exclusivamente do uso da _CPU_. O c√≥digo
da se√ß√£o anterior √© um exemplo de _I/O-bound_.

### Threads e I/O

O Sistema Operacional √© respons√°vel pelo gerenciamento de uma _thread_. [Ele a interrompe a qualquer momento, salva o seu estado, e executa qualquer outra em seu lugar,
podendo resumi-la ao fim do processo](https://en.wikipedia.org/wiki/Preemption_%28computing%29#Preemptive_multitasking "Preemption (computing)").

_Larry Hastings_, no ["Python's Infamous GIL"](https://www.youtube.com/watch?t=11m40s&v=4zeHStBowEk&feature=youtu.be "Veja o talk no Youtube"), descreve
como o gerenciamento da _GIL_ funciona do ponto de vista da linguagem:

> The way Python threads work with the GIL is with a simple counter. With every 100 byte codes executed the
> GIL is supposed to be released by the thread currently executing in order to give other threads a chance to execute code.

Quando acessamos um banco de dados em outro servidor, um servi√ßo _web_, ou um arquivo em um sistema de arquivos, estamos
realizando uma opera√ß√£o _I/O-bound_. Qualquer a√ß√£o que demande comunica√ß√£o com o _hardware_ (como os _sockets_), envolve comunica√ß√£o
com o _kernel_ da m√°quina, e essa opera√ß√£o √© mais lenta que as opera√ß√µes de uma _CPU_.

![Diagrama de tempo comparando I/O waiting e CPU processing com Threads](/media/iobound.png "I/O e CPU em um contexto I/O-Bound com Threads (realpython.com)")

Como resultado, a maioria das opera√ß√µes _I/O-bound_ ficar√° em um estado de "espera" at√© o momento em que ela receba um resultado. E como afirma _Cody Piersall_,
nessa [incrivelmente simples resposta no _Stackoverflow_](https://stackoverflow.com/questions/32256775/how-does-the-gil-in-python-affect-the-downloading-of-webpages-in-parallel "How does the GIL in python affect the downloading of webpages in parallel?"):

> The GIL won't hurt you here.
>
> For I/O bound tasks (like downloading webpages), the GIL is not a problem. Python releases the GIL when I/O is happening,
> which means all the threads will be able execute the requests in parallel.

Em outras palavras, a _thread_ que necessita pegar dados de uma fonte externa ir√° adquirir a _GIL_. Subseq√ºentemente o _lock_ √© liberado
e √© adquirido por outra _thread_ que inicia outro c√≥digo _I/O-bound_ (por exemplo). Quando a _GIL_ √© adquirida novamente pela primeira _thread_, possivelmente
ela j√° tenha recebido os dados.

![Fluxograma com threads e os passos de acquire GIL, waiting for GIL, e releasing GIL](/media/gil-lock-threads.png "Exemplo onde a GIL √© aquirida e liberada em diferentes threads (medium.com/fintechexplained)")

Some isso ao fato de que [criar novos processos √© normalmente mais caro do que _threads_](https://stackoverflow.com/questions/3044580/multiprocessing-vs-threading-python] "Multiprocessing vs Threading Python [duplicate]"), e temos uma resposta satisfat√≥ria aos n√∫meros
apresentados no experimento anterior.

Portanto, se:

- _CPU-bound_: Use _multiprocessing_;
- _I/O-bound_: Use _threads_ ou _asyncio_.

## Async

E voltamos ao _asynchronous_, afinal esse √© um _post_ sobre _ASGI_ üôÇ

Segundo _Miguel Grinberg_, no _talk_ ["Asynchronous Python for the Complete Beginner"](https://www.youtube.com/watch?v=iG6fr81xHKA "Veja a apresenta√ß√£o na √≠ntegra"), _async_
√©:

> A style of concurrent programming in which tasks release the CPU during waiting
> periods, so that other tasks can use it.

√â importante salientar que:

- _Async_ (_async IO_, _asynchoronous_, ou _asynchronous IO_) e _asyncio_ n√£o s√£o exatamente a mesma coisa;
- O _asynchronous IO_, de forma geral, √© um estilo de programa√ß√£o concorrente;
- J√° o [_asyncio_](https://docs.python.org/3/library/asyncio.html "Leia mais na documenta√ß√£o oficial") √© uma das implementa√ß√µes _Python_ desse estilo (h√° outras implementa√ß√µes,
  como o [_uvloop_](http://github.com/MagicStack/uvloop "Veja o reposit√≥rio")).

Continuamos dentro dos dom√≠nios da concorr√™ncia, mas ainda assim, apresentando uma t√©cnica completamente diferente.

### Event loop

De forma simplista, imagine que h√° um objeto _Python_ chamado de _event loop_, e esse camarada √©
quem controla como e quando cada _task_ ir√° rodar. Ele √© consciente de cada _task_,
e sabe em qual estado cada uma est√°.

![Ilustra√ß√£o mostrando de forma subjetiva como o event loop funciona](/media/python-event-loop.png "O event loop √© um pouco abstrato, e n√£o consegui pensar em nenhum diagrama para explic√°-lo (fadeevab.com)")

Por exemplo, o estado "pronto" indica que a tarefa tem trabalho a fazer e est√° pronta para rodar. O "esperando" indica
que a tarefa est√° esperando que alguma coisa externa termine, como as _I/O-bounds operations_ que discutimos anteriormente.

Para deixar as coisas simples, vamos imaginar que o _event loop_ mantenha uma lista para tarefas "prontas para executar", e outra para "esperando". Ele
pega uma das _tasks_ prontas para executar e bota para rodar. E aqui vai um detalhe importante: [A tarefa ter√° total controle da execu√ß√£o at√© o momento que
ela, cooperativamente, devolve o controle para o _event loop_](https://en.wikipedia.org/wiki/Cooperative_multitasking "Cooperative multitasking").

Quando a tarefa devolve o controle para o _event loop_, ele a coloca na determinada fila dependendo do seu estado. Ele (o _event loop_) percorre a lista de tarefas "esperando"
para checar se o _I/O_ de alguma delas j√° acabou, e portanto, se o seu estado agora √© "pronta para executar". Essa tarefa √© ent√£o movida para a lista de prontos para executar,
e o _event loop_ pega a pr√≥xima tarefa dessa mesma lista.

![Diagrama de tempo comparando I/O waiting e CPU processing com asyncio](/media/iobound-asyncio.png "I/O e CPU em um contexto I/O-Bound com asyncio (realpython.com)")

E o processo se repete.

### asyncio x multithreading

O _async_ e _threads_ podem at√© parecer ter algumas semelhan√ßas, mas h√° muitas diferen√ßas. Para come√ßar, as "tarefas" no contexto
do _asyncio_ s√£o chamadas de _coroutines_. Recorremos ao [_Stackoverflow_ para deixar as coisas mais claras](https://stackoverflow.com/questions/1934715/difference-between-a-coroutine-and-a-thread "Difference between a ‚Äúcoroutine‚Äù and a ‚Äúthread‚Äù?"):

> With threads, the operating system switches running threads preemptively according to its scheduler, which is an algorithm in
> the operating system kernel. With coroutines, the programmer and programming language determine when to switch coroutines;
> in other words, tasks are cooperatively multitasked by pausing and resuming functions at set points, typically (but not
> necessarily) within a single thread.

Duas coisas importantes precisam ser observadas com essa afirma√ß√£o:

1. Tarefas nunca s√£o interrompidas no meio de uma opera√ß√£o, portanto, √© mais f√°cil e seguro compartilhar recursos com _asyncio_ em compara√ß√£o com _threads_.
2. √â isso mesmo que voc√™ leu: Tipicamente (mas n√£o necessariamente) dentro de uma √∫nica _thread_.

Outro ponto importante √© que assim como _threads_, corrotinas s√£o mais leves que subprocessos. Mas aposto que voc√™ ainda est√° chocado com o _single-thread_, ent√£o
vamos voltar a ele.

### O exemplo da enxadrista

O _asyncio_ √© ([por padr√£o](https://docs.python.org/3/library/asyncio-dev.html#concurrency-and-multithreading "Concurrency and Multithreading")) _single-threaded_ e _single-process_. Como ele consegue ser uma alternativa t√£o interessante quanto os seus primos?

![Protagonista de Gambit's Queen jogando xadrez](/media/queens-gambit.jpg "Achou que n√£o ia ter refer√™ncia ao Gambito? (lifestyleasia.com)")

Voltamos a citar o _RealPython_, [trazendo o exemplo da enxadrista](https://realpython.com/async-io-python/ "Async IO in Python"):

> Chess master Judit Polg√°r hosts a chess exhibition in which she plays multiple amateur players.
> She has two ways of conducting the exhibition: synchronously and asynchronously.
>
> Assumptions
>
> - 24 opponents
> - Judit makes each chess move in 5 seconds
> - Opponents each take 55 seconds to make a move
> - Games average 30 pair-moves (60 moves total)
>
> **Synchronous version:** Judit plays one game at a time, never two at the same time, until the game is complete.
> Each game takes (55 + 5) _ 30 == 1800 seconds, or 30 minutes. The entire exhibition takes 24 _ 30 == 720 minutes, or **12 hours**.
>
> **Asynchronous version:** Judit moves from table to table, making one move at each table. She leaves the table and lets the opponent
> make their next move during the wait time. One move on all 24 games takes Judit 24 _ 5 == 120 seconds, or 2 minutes.
> The entire exhibition is now cut down to 120 _ 30 == 3600 seconds, or just **1 hour**.

Temos apenas uma _Judit_, que pode fazer um movimento por vez por ela mesma. Ela jogar cada jogo de forma s√≠ncrona limita ela
tamb√©m ao tempo que o outro enxadrista tem para respond√™-la. Mas de forma ass√≠ncrona, ela consegue lidar com m√∫ltiplas tarefas acontecendo concorrentemente,
em turnos que permitem que ao tempo que um enxadrista est√° pensando em uma resposta, ela se move para o pr√≥ximo, e retorna quando o primeiro estiver pronto.

Imagine que _Judit_ √© o _event loop_, e que as jogadas com os 24 oponentes s√£o tarefas acontecendo concorrentemente.

### async/await

Mas como?

O _Python_ apresenta algumas palavras reservadas que permitem informar ao _event loop_ o estado da tarefa sendo executada.
Voc√™ provavelmente j√° ouviu falar das principais: `async` e `await`.

Com a primeira, indicamos ao _Python_ que uma fun√ß√£o trata-se de uma corrotina (ou um [_generator_ ass√≠ncrono](https://www.python.org/dev/peps/pep-0525/ "Leia a PEP 525")).
J√° com o `await`, estamos dando o controle de volta ao _event loop_, e sinalizando que podemos esperar pelo resultado de determinada opera√ß√£o.

Ou seja, com o c√≥digo abaixo:

```python
async def g():
    r = await f()
    return r
```

Queremos dizer:

```text
Suspenda a execu√ß√£o de g(),
at√© que o que quer que a gente esteja esperando em f()
seja retornado.

Nesse meio tempo, v√° executar alguma outra coisa...
```

E note que bibliotecas para _I/O_ precisam suportar essa forma de escrita, caso contr√°rio n√£o estaremos de fato fazendo uso das propriedades do _async_.

### Na pr√°tica

Voltamos ao mesmo exemplo usado com _threads_ e _multiprocessing_, mas agora reescrito para utilizar a biblioteca `asyncio`:

```python
# async.py

import asyncio
import httpx
import itertools

URLS = ['http://www.foxnews.com/',
        'http://www.cnn.com/',
        'http://www.bbc.co.uk/', ]


async def measure_url(client, url):
    resp = await client.get(url)
    length = len(resp.text)
    return (url, length)


async def main():
    async with httpx.AsyncClient() as client:
        results = await asyncio.gather(
            *map(measure_url, itertools.repeat(client), URLS)
        )

    for (url, length) in results:
        print(f"{url} tem {length} bytes")


if __name__ == "__main__":
    asyncio.run(main())

```

Note o uso das palavras reservadas `async` e `await`, e do inicializador do _event loop_. Al√©m, claro,
do uso de bibliotecas n√£o bloqueantes como o caso da [_httpx_](https://www.python-httpx.org "A next-generation HTTP client for Python").

E como fica o comparativo com _threads_ e processos? Mais uma vez rodando com `time`, temos:

```text
$ time python async.py
http://www.foxnews.com/ tem 339756 bytes
http://www.cnn.com/ tem 1145150 bytes
http://www.bbc.co.uk/ tem 317556 bytes
python async.py  0.22s user 0.07s system 13% cpu 2.151 total
```

Nada mal. Quase metade do tempo usando `multiprocessing`, e um pouco mais que usando _threads_. Isso n√£o quer
dizer que _asyncio_ √© necessariamento mais lento, [apenas que o contexto desse experimento favoreceu o exemplo com _threads_](https://stackoverflow.com/questions/8546273/is-non-blocking-i-o-really-faster-than-multi-threaded-blocking-i-o-how "Is non-blocking I/O really faster than multi-threaded blocking I/O? How?").

O prop√≥sito do comparativo com `time` nesse artigo √© apenas ilustrar que h√° diferen√ßa entre as op√ß√µes poss√≠veis. Mas se
voc√™ n√£o est√° satisfeito com o resultado, o _Stackoverflow_ [pode ajudar novamente](https://stackoverflow.com/questions/27435284/multiprocessing-vs-multithreading-vs-asyncio-in-python-3 "multiprocessing vs multithreading vs asyncio in Python 3"):

> - CPU Bound => Multi Processing
> - I/O Bound, Fast I/O, Limited Number of Connections => Multi Threading
> - I/O Bound, Slow I/O, Many connections => Asyncio

Vai depender do contexto do problema sendo resolvido.

## Considera√ß√µes finais

Eu lembro de estar em mais de uma entrevista de emprego, e ser perguntado
sobre como fazer _CPU-bound_ e _IO-bound_ em _Python_.

Agora sabemos o b√°sico sobre os principais conceitos relacionados √† concorr√™ncia em _Python_. Temos uma perspectiva
mais detalhada sobre a _GIL_, e n√£o entramos no m√©rito de debater se ela √© boa ou ruim.
Entender a natureza das _threads_ na linguagem √© mais importante, e √© crucial para decidirmos da melhor forma como solucionar
problemas concorrentes.

E optar pelo _async/ASGI_ faz parte disso tamb√©m. Portanto, agora que temos todo o contexto de concorr√™ncia e paralelismo,
no pr√≥ximo _post_ vamos revisitar o funcionamento do _WSGI_, compar√°-lo com o seu primo mais novo, e compreender a motiva√ß√£o por tr√°s da alternativa.

At√© a pr√≥xima.

## Refer√™ncias

- [CallHub - Understanding Python GIL](https://callhub.io/understanding-python-gil/)
- [Dev.to - Multi-threading vs Event Loop in Python](https://dev.to/mervynlee94/multi-threading-vs-event-loop-in-python-1h4h)
- [Diogo M Martins - Concorr√™ncia e paralelismo: Threads, m√∫ltiplos processos e asyncio - Parte 1](https://diogommartins.wordpress.com/2017/04/07/concorrencia-e-paralelismo-threads-multiplos-processos-e-asyncio-parte-1/)
- [FinTechExplained - Advanced Python: Concurrency And Parallelism](https://medium.com/fintechexplained/advanced-python-concurrency-and-parallelism-82e378f26ced)
- [FullStackAI - Concurrency in Python: Cooperative vs Preemptive Scheduling](https://medium.com/fullstackai/concurrency-in-python-cooperative-vs-preemptive-scheduling-5feaed7f6e53)
- [Gitconnected - DIY: Multithreading vs Multiprocessing in Python](https://levelup.gitconnected.com/diy-multithreading-vs-multiprocessing-in-python-fb93698ca7f3)
- [Miguel Grinberg - Sync vs. Async Python: What is the Difference?](https://blog.miguelgrinberg.com/post/sync-vs-async-python-what-is-the-difference)
- [Oxford Protein Informatics Group - Making the most of your CPUs when using python](https://www.blopig.com/blog/2019/01/making-the-most-of-your-cpus-when-using-python/)
- [RealPython - Async IO in Python: A Complete Walkthrough](https://realpython.com/async-io-python/)
- [RealPython - Speed Up Your Python Program With Concurrency](https://realpython.com/python-concurrency/)
- [RealPython - What Is the Python Global Interpreter Lock (GIL)?](https://realpython.com/python-gil/)
- [Stackify - Python Garbage Collection: What It Is and How It Works](https://stackify.com/python-garbage-collection/)
- [Stackoverflow - Difference between a ‚Äúcoroutine‚Äù and a ‚Äúthread‚Äù?](https://stackoverflow.com/questions/1934715/difference-between-a-coroutine-and-a-thread)
- [Stackoverflow - How does python handle thread locking / context switching?](https://stackoverflow.com/questions/33352298/how-does-python-handle-thread-locking-context-switching)
- [Stackoverflow - Is non-blocking I/O really faster than multi-threaded blocking I/O? How?](https://stackoverflow.com/questions/8546273/is-non-blocking-i-o-really-faster-than-multi-threaded-blocking-i-o-how)
- [Stackoverflow - multiprocessing vs multithreading vs asyncio in Python 3](https://stackoverflow.com/questions/27435284/multiprocessing-vs-multithreading-vs-asyncio-in-python-3)
- [Stackoverflow - Multiprocessing vs Threading Python [duplicate]](https://stackoverflow.com/questions/3044580/multiprocessing-vs-threading-python)
- [Stackoverflow - What do the terms ‚ÄúCPU bound‚Äù and ‚ÄúI/O bound‚Äù mean?](https://stackoverflow.com/questions/868568/what-do-the-terms-cpu-bound-and-i-o-bound-mean)
- [Stackoverflow - What is the difference between concurrency and parallelism?](https://stackoverflow.com/questions/1050222/what-is-the-difference-between-concurrency-and-parallelism)
- [Testdriven.io - Parallelism, Concurrency, and AsyncIO in Python - by example](https://testdriven.io/blog/python-concurrency-parallelism/)
- [Timber - Multiprocessing Vs. Threading In Python: What You Need To Know.](https://timber.io/blog/multiprocessing-vs-multithreading-in-python-what-you-need-to-know/)
- [Youtube - Miguel Grinberg Asynchronous Python for the Complete Beginner PyCon 2017](https://www.youtube.com/watch?v=iG6fr81xHKA)
